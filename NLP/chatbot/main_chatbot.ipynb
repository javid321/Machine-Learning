{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = json.loads(open('./intents.json').read())\n",
    "\n",
    "intents_df = pd.read_json('./intents.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "df_chat = pd.json_normalize(intents, record_path =['intents'])\n",
    "df_chat = df_chat[['tag', 'patterns']]\n",
    "df_chat = df_chat.explode(['patterns'], ignore_index=True)\n",
    "df_chat = pd.DataFrame(df_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(df_chat['tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = word_tokenize\n",
    "vectorizer_bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(word):\n",
    "    words = tokenizer(word)\n",
    "    words = [lemmatizer.lemmatize(text) for text in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagofword(text):\n",
    "    word = lemm(text)\n",
    "    bag = vectorizer_bow.transform(word)\n",
    "    return bag.toarray()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(t):\n",
    "#     bow = bagofword(t)\n",
    "#     res = model.predict(bow)[0]\n",
    "#     error_treshold = 0.25\n",
    "#     result = [[i,r] for i,r in enumerate(res) if r > error_treshold]\n",
    "    \n",
    "#     result.sort(key=lambda x: x[1],reverse=True)\n",
    "#     return_list =[]\n",
    "#     for r in result:\n",
    "#         return_list.append({'intents': classes[r[0]], 'probability' : str(r[1])})\n",
    "#     return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(t):\n",
    "    bow = bagofword(t)\n",
    "    result = model.predict(bow)[0]\n",
    "    print('result : {}'.format(result))\n",
    "    error_treshold = 0.85\n",
    "    if result[result_index] >= error_treshold:\n",
    "        result_index = np.argmax(result)\n",
    "    else:\n",
    "        result_index = 'unknown'\n",
    "    \n",
    "    return result_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(res_index, intent_json):\n",
    "    if res_index=='unknown':\n",
    "        result = 'I\\'m sorry, I didnt get it'\n",
    "    else:\n",
    "        tag = classes[res_index]\n",
    "        print('tag : {}'.format(tag))\n",
    "        list_of_intent = intent_json['intents']\n",
    "        for i in list_of_intent:\n",
    "            if i['tag'] == tag:\n",
    "                result=random.choice(i['responses'])\n",
    "                break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot is Running\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mif\u001b[39;00m message\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m message\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mquit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m ints \u001b[39m=\u001b[39m predict(message)\n\u001b[0;32m      7\u001b[0m response \u001b[39m=\u001b[39m get_response(ints, intents)\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAnda : \u001b[39m\u001b[39m'\u001b[39m,message)\n",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(t):\n\u001b[1;32m----> 2\u001b[0m     bow \u001b[39m=\u001b[39m bagofword(t)\n\u001b[0;32m      3\u001b[0m     result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(bow)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mresult : \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(result))\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mbagofword\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbagofword\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     word \u001b[39m=\u001b[39m lemm(text)\n\u001b[1;32m----> 3\u001b[0m     bag \u001b[39m=\u001b[39m vectorizer_bow\u001b[39m.\u001b[39mtransform(word)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m bag\u001b[39m.\u001b[39mtoarray()\n",
      "File \u001b[1;32mc:\\Users\\ARSY\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1430\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(raw_documents, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1427\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIterable over raw text documents expected, string object received.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1429\u001b[0m     )\n\u001b[1;32m-> 1430\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_vocabulary()\n\u001b[0;32m   1432\u001b[0m \u001b[39m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[0;32m   1433\u001b[0m _, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_count_vocab(raw_documents, fixed_vocab\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ARSY\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:510\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_vocabulary()\n\u001b[0;32m    509\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed_vocabulary_:\n\u001b[1;32m--> 510\u001b[0m         \u001b[39mraise\u001b[39;00m NotFittedError(\u001b[39m\"\u001b[39m\u001b[39mVocabulary not fitted or provided\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabulary_) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    513\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mVocabulary is empty\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "print('Bot is Running')\n",
    "while True:\n",
    "    message = input(\"Anda : \")\n",
    "    if message.lower() == \"stop\" or message.lower() == \"quit\":\n",
    "        break\n",
    "    ints = predict(message)\n",
    "    response = get_response(ints, intents)\n",
    "    print('Anda : ',message)\n",
    "    print('Bot : ',response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
